name: Mask Aware Autoencoder Builder V2
description: Build a Mask-Aware Autoencoder model in PyTorch from YAML configuration and save as .pth file
inputs:
  # Model Architecture Parameters
  - {name: feature_dim, type: Integer, description: "Number of input features (e.g., 16197)", default: "16197"}
  - {name: latent_dim, type: Integer, description: "Latent space dimension (e.g., 128)", default: "1024"}

  # Encoder Layer Configuration
  - {name: encoder_layers, type: String, description: "Comma-separated encoder layer sizes e.g. 1024,512,256", default: "1024,256,256,256,256"}
  - {name: encoder_activation, type: String, description: "Encoder activation function (relu, tanh, elu)", default: "relu"}
  - {name: encoder_dropout, type: Float, description: "Encoder dropout rate", default: "0.0"}
  - {name: encoder_batch_norm, type: String, description: "Use batch normalization in encoder (true/false)", default: "false"}

  # Decoder Layer Configuration
  - {name: decoder_layers, type: String, description: "Comma-separated decoder layer sizes e.g. 256,512,1024", default: "1024,256,1024,256,256"}
  - {name: decoder_activation, type: String, description: "Decoder activation function (relu, tanh, elu)", default: "relu"}
  - {name: decoder_dropout, type: Float, description: "Decoder dropout rate", default: "0.0"}
  - {name: decoder_batch_norm, type: String, description: "Use batch normalization in decoder (true/false)", default: "false"}

  # Initialization
  - {name: weight_init, type: String, description: "Weight initialization method (xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal)", default: "xavier_uniform"}
  - {name: bias_init, type: String, description: "Bias initialization method (zeros, ones, uniform)", default: "zeros"}

  # Model Metadata
  - {name: model_name, type: String, description: "Name for the saved model", default: "mask_aware_autoencoder"}
  - {name: random_seed, type: Integer, description: "Random seed for reproducibility", default: "42"}

outputs:
  - {name: model_file, type: Model, description: "Built PyTorch model saved as .pth file"}
  - {name: model_config, type: Data, description: "Model configuration JSON file"}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v1
    command:
      - python3
      - -u
      - -c
      - |
        import os
        import sys
        import argparse
        import traceback
        import json
        import torch
        import torch.nn as nn

        # ============================================
        # Argument Parser
        # ============================================
        parser = argparse.ArgumentParser(description="Build Mask-Aware Autoencoder Model")

        # Model architecture
        parser.add_argument("--feature_dim", type=int, required=True)
        parser.add_argument("--latent_dim", type=int, required=True)

        # Encoder config
        parser.add_argument("--encoder_layers", type=str, required=True,
                            help="Comma-separated encoder layer sizes e.g. 1024,512,256")
        parser.add_argument("--encoder_activation", type=str, required=True)
        parser.add_argument("--encoder_dropout", type=float, required=True)
        parser.add_argument("--encoder_batch_norm", type=str, required=True)

        # Decoder config
        parser.add_argument("--decoder_layers", type=str, required=True,
                            help="Comma-separated decoder layer sizes e.g. 256,512,1024")
        parser.add_argument("--decoder_activation", type=str, required=True)
        parser.add_argument("--decoder_dropout", type=float, required=True)
        parser.add_argument("--decoder_batch_norm", type=str, required=True)

        # Initialization
        parser.add_argument("--weight_init", type=str, required=True)
        parser.add_argument("--bias_init", type=str, required=True)

        # Metadata
        parser.add_argument("--model_name", type=str, required=True)
        parser.add_argument("--random_seed", type=int, required=True)

        # Outputs
        parser.add_argument("--model_file", type=str, required=True)
        parser.add_argument("--model_config", type=str, required=True)

        args = parser.parse_args()

        print("[model_builder] Starting Mask-Aware Autoencoder model building...")
        print(f"[model_builder] Feature dimension: {args.feature_dim}")
        print(f"[model_builder] Latent dimension: {args.latent_dim}")
        print(f"[model_builder] Encoder layers: {args.encoder_layers}")
        print(f"[model_builder] Decoder layers: {args.decoder_layers}")

        # ============================================
        # Set Random Seed
        # ============================================
        torch.manual_seed(args.random_seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(args.random_seed)
        print(f"[model_builder] Random seed set to: {args.random_seed}")

        # ============================================
        # Helper Functions
        # ============================================
        def str_to_bool(s):
            return s.lower() in ['true', '1', 'yes']

        def parse_layers(layers_str):
            """Parse comma-separated string into list of integers.
            e.g. '1024,512,256' -> [1024, 512, 256]
            """
            try:
                return [int(x.strip()) for x in layers_str.split(",") if x.strip()]
            except ValueError as e:
                raise ValueError(f"Invalid layer sizes format '{layers_str}'. "
                                 f"Expected comma-separated integers e.g. '1024,512,256'. Error: {e}")

        def get_activation(name):
            activations = {
                'relu': nn.ReLU(),
                'tanh': nn.Tanh(),
                'elu': nn.ELU(),
                'leaky_relu': nn.LeakyReLU(),
                'sigmoid': nn.Sigmoid(),
                'none': None
            }
            return activations.get(name.lower(), nn.ReLU())

        def init_weights(module, weight_init, bias_init):
            if isinstance(module, nn.Linear):
                # Weight initialization
                if weight_init == 'xavier_uniform':
                    nn.init.xavier_uniform_(module.weight)
                elif weight_init == 'xavier_normal':
                    nn.init.xavier_normal_(module.weight)
                elif weight_init == 'kaiming_uniform':
                    nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')
                elif weight_init == 'kaiming_normal':
                    nn.init.kaiming_normal_(module.weight, nonlinearity='relu')
                else:
                    nn.init.xavier_uniform_(module.weight)

                # Bias initialization
                if module.bias is not None:
                    if bias_init == 'zeros':
                        nn.init.zeros_(module.bias)
                    elif bias_init == 'ones':
                        nn.init.ones_(module.bias)
                    elif bias_init == 'uniform':
                        nn.init.uniform_(module.bias, -0.1, 0.1)
                    else:
                        nn.init.zeros_(module.bias)

        # ============================================
        # Model Definitions
        # ============================================
        class MAEEncoder(nn.Module):
            def __init__(self, feature_dim, latent_dim,
                         layer_sizes, activation, dropout, batch_norm):
                super(MAEEncoder, self).__init__()

                # Input = [x, mask] concatenated -> 2 * feature_dim
                input_dim = 2 * feature_dim
                prev_dim = input_dim
                layers = []

                print(f"[model_builder] Building Encoder...")
                print(f"[model_builder]   Input dim: {input_dim} (features + mask concatenated)")

                # Dynamically build N hidden layers from layer_sizes list
                for idx, units in enumerate(layer_sizes):
                    layers.append(nn.Linear(prev_dim, units))

                    if batch_norm:
                        layers.append(nn.BatchNorm1d(units))

                    if activation is not None:
                        layers.append(activation)

                    if dropout > 0:
                        layers.append(nn.Dropout(dropout))

                    print(f"[model_builder]   Encoder Layer {idx + 1}: {prev_dim} -> {units}")
                    prev_dim = units

                # Final projection to latent space
                layers.append(nn.Linear(prev_dim, latent_dim))
                print(f"[model_builder]   Encoder Latent Output: {prev_dim} -> {latent_dim}")

                self.encoder = nn.Sequential(*layers)

            def forward(self, x, m):
                # Concatenate features and mask along feature dimension
                x_in = torch.cat([x, m], dim=1)
                return self.encoder(x_in)

        class MAEDecoder(nn.Module):
            def __init__(self, feature_dim, latent_dim,
                         layer_sizes, activation, dropout, batch_norm):
                super(MAEDecoder, self).__init__()

                prev_dim = latent_dim
                layers = []

                print(f"[model_builder] Building Decoder...")
                print(f"[model_builder]   Input dim: {latent_dim} (latent space)")

                # Dynamically build N hidden layers from layer_sizes list
                for idx, units in enumerate(layer_sizes):
                    layers.append(nn.Linear(prev_dim, units))

                    if batch_norm:
                        layers.append(nn.BatchNorm1d(units))

                    if activation is not None:
                        layers.append(activation)

                    if dropout > 0:
                        layers.append(nn.Dropout(dropout))

                    print(f"[model_builder]   Decoder Layer {idx + 1}: {prev_dim} -> {units}")
                    prev_dim = units

                # Final projection back to original feature space
                layers.append(nn.Linear(prev_dim, feature_dim))
                print(f"[model_builder]   Decoder Reconstruction Output: {prev_dim} -> {feature_dim}")

                self.decoder = nn.Sequential(*layers)

            def forward(self, z):
                return self.decoder(z)

        class MaskAwareAutoencoder(nn.Module):
            def __init__(self, feature_dim, latent_dim,
                         encoder_config, decoder_config):
                super(MaskAwareAutoencoder, self).__init__()

                self.feature_dim = feature_dim
                self.latent_dim = latent_dim

                self.encoder = MAEEncoder(
                    feature_dim=feature_dim,
                    latent_dim=latent_dim,
                    layer_sizes=encoder_config['layer_sizes'],
                    activation=encoder_config['activation'],
                    dropout=encoder_config['dropout'],
                    batch_norm=encoder_config['batch_norm']
                )

                self.decoder = MAEDecoder(
                    feature_dim=feature_dim,
                    latent_dim=latent_dim,
                    layer_sizes=decoder_config['layer_sizes'],
                    activation=decoder_config['activation'],
                    dropout=decoder_config['dropout'],
                    batch_norm=decoder_config['batch_norm']
                )

            def forward(self, x, m):
                z = self.encoder(x, m)
                x_hat = self.decoder(z)
                return x_hat, z

        # ============================================
        # Build Model
        # ============================================
        try:
            print("[model_builder] Building model architecture...")

            # Parse layer sizes from comma-separated strings
            encoder_layer_sizes = parse_layers(args.encoder_layers)
            decoder_layer_sizes = parse_layers(args.decoder_layers)

            print(f"[model_builder] Encoder layer sizes parsed: {encoder_layer_sizes}")
            print(f"[model_builder] Decoder layer sizes parsed: {decoder_layer_sizes}")

            # Parse configurations
            encoder_config = {
                'layer_sizes': encoder_layer_sizes,
                'activation': get_activation(args.encoder_activation),
                'dropout': args.encoder_dropout,
                'batch_norm': str_to_bool(args.encoder_batch_norm)
            }

            decoder_config = {
                'layer_sizes': decoder_layer_sizes,
                'activation': get_activation(args.decoder_activation),
                'dropout': args.decoder_dropout,
                'batch_norm': str_to_bool(args.decoder_batch_norm)
            }

            # Create model
            model = MaskAwareAutoencoder(
                feature_dim=args.feature_dim,
                latent_dim=args.latent_dim,
                encoder_config=encoder_config,
                decoder_config=decoder_config
            )

            print(f"[model_builder] Model created successfully")
            print(f"[model_builder] Total parameters: {sum(p.numel() for p in model.parameters()):,}")
            print(f"[model_builder] Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

            # Initialize weights
            print(f"[model_builder] Initializing weights with: {args.weight_init}")
            print(f"[model_builder] Initializing biases with: {args.bias_init}")
            model.apply(lambda m: init_weights(m, args.weight_init, args.bias_init))

            # ============================================
            # Save Model
            # ============================================
            os.makedirs(args.model_file, exist_ok=True)
            model_path = os.path.join(args.model_file, f"{args.model_name}.pth")

            # Prepare checkpoint
            checkpoint = {
                'model_state_dict': model.state_dict(),
                'model_config': {
                    'feature_dim': args.feature_dim,
                    'latent_dim': args.latent_dim,
                    'encoder': {
                        'layer_sizes': encoder_layer_sizes,
                        'num_layers': len(encoder_layer_sizes),
                        'activation': args.encoder_activation,
                        'dropout': args.encoder_dropout,
                        'batch_norm': args.encoder_batch_norm
                    },
                    'decoder': {
                        'layer_sizes': decoder_layer_sizes,
                        'num_layers': len(decoder_layer_sizes),
                        'activation': args.decoder_activation,
                        'dropout': args.decoder_dropout,
                        'batch_norm': args.decoder_batch_norm
                    },
                    'initialization': {
                        'weight_init': args.weight_init,
                        'bias_init': args.bias_init,
                        'random_seed': args.random_seed
                    }
                },
                'model_name': args.model_name,
                'architecture': 'MaskAwareAutoencoder',
                'version': '2.0'
            }

            torch.save(checkpoint, model_path)
            print(f"[model_builder] Model saved to: {model_path}")

            # Verify saved model
            file_size = os.path.getsize(model_path)
            print(f"[model_builder] Model file size: {file_size:,} bytes ({file_size/(1024*1024):.2f} MB)")

            # Test loading
            loaded = torch.load(model_path, map_location='cpu')
            print(f"[model_builder] Model verification: Successfully loaded checkpoint")
            print(f"[model_builder] Checkpoint keys: {list(loaded.keys())}")

            # ============================================
            # Save Configuration JSON
            # ============================================
            os.makedirs(args.model_config, exist_ok=True)
            config_path = os.path.join(args.model_config, "model_config.json")

            config_dict = checkpoint['model_config'].copy()
            config_dict['model_name'] = args.model_name
            config_dict['total_parameters'] = sum(p.numel() for p in model.parameters())
            config_dict['trainable_parameters'] = sum(p.numel() for p in model.parameters() if p.requires_grad)

            with open(config_path, 'w') as f:
                json.dump(config_dict, f, indent=2)

            print(f"[model_builder] Configuration saved to: {config_path}")

            # ============================================
            # Print Model Summary
            # ============================================
            print("=" * 60)
            print("MODEL SUMMARY")
            print("=" * 60)
            print(f"Model Name    : {args.model_name}")
            print(f"Architecture  : Mask-Aware Autoencoder v2.0")
            print(f"")
            print(f"ENCODER")
            print(f"  Input       : {2 * args.feature_dim} (features + mask concatenated)")
            for idx, units in enumerate(encoder_layer_sizes):
                print(f"  Layer {idx + 1:<4}  : {units} units | act={args.encoder_activation} | dropout={args.encoder_dropout} | bn={args.encoder_batch_norm}")
            print(f"  Latent      : {args.latent_dim}")
            print(f"")
            print(f"DECODER")
            print(f"  Input       : {args.latent_dim} (latent space)")
            for idx, units in enumerate(decoder_layer_sizes):
                print(f"  Layer {idx + 1:<4}  : {units} units | act={args.decoder_activation} | dropout={args.decoder_dropout} | bn={args.decoder_batch_norm}")
            print(f"  Output      : {args.feature_dim} (reconstructed features)")
            print(f"")
            print(f"Total Parameters    : {sum(p.numel() for p in model.parameters()):,}")
            print(f"Trainable Params    : {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
            print("=" * 60)

            print("[model_builder] Model building completed successfully!")

        except Exception as e:
            print(f"[model_builder] ERROR: Failed to build model: {e}")
            traceback.print_exc()
            sys.exit(1)

    args:
      # Model architecture
      - --feature_dim
      - {inputValue: feature_dim}
      - --latent_dim
      - {inputValue: latent_dim}

      # Encoder config
      - --encoder_layers
      - {inputValue: encoder_layers}
      - --encoder_activation
      - {inputValue: encoder_activation}
      - --encoder_dropout
      - {inputValue: encoder_dropout}
      - --encoder_batch_norm
      - {inputValue: encoder_batch_norm}

      # Decoder config
      - --decoder_layers
      - {inputValue: decoder_layers}
      - --decoder_activation
      - {inputValue: decoder_activation}
      - --decoder_dropout
      - {inputValue: decoder_dropout}
      - --decoder_batch_norm
      - {inputValue: decoder_batch_norm}

      # Initialization
      - --weight_init
      - {inputValue: weight_init}
      - --bias_init
      - {inputValue: bias_init}

      # Metadata
      - --model_name
      - {inputValue: model_name}
      - --random_seed
      - {inputValue: random_seed}

      # Outputs
      - --model_file
      - {outputPath: model_file}
      - --model_config
      - {outputPath: model_config}
